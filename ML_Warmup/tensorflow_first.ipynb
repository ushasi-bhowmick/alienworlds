{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#weight tensor matrix multiplied with weight tensor, then add bias, then take an activation function to get output\r\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tf.compat.v1.disable_eager_execution()\r\n",
    "hello_const = tf.constant('Hello world')\r\n",
    "hello_const"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=string>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\r\n",
    "a = tf.constant(5.0)\r\n",
    "b = tf.constant(6.0)\r\n",
    "c = a * b\r\n",
    "sess = tf.compat.v1.Session()\r\n",
    "print(sess.run(c)) \r\n",
    "print(sess.run(hello_const))\r\n",
    "sess.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30.0\n",
      "b'Hello world'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#difference between placeholder and variables?\r\n",
    "val1=tf.compat.v1.placeholder(tf.float32)\r\n",
    "val2=tf.compat.v1.placeholder(tf.float32)\r\n",
    "summ = val1+val2\r\n",
    "sess= tf.compat.v1.Session()\r\n",
    "#now instead of passing values we can pass dictionary, so it can be consts, arrays, matrices and what not\r\n",
    "print(sess.run(summ,feed_dict={val1:[1,2,3,4],val2:[5,6,7,8]}))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 6.  8. 10. 12.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "mult = val1*val2\r\n",
    "print(sess.run(mult,feed_dict={val1:[[1,2],[3,4]],val2:[[5,6],[7,8]]}))\r\n",
    "sess.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 5. 12.]\n",
      " [21. 32.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#variables are trainable parameters to graph... stuff that we can change later on...\r\n",
    "#we need to initialise the variable by explicit function... extra layer of protection for running large computation\r\n",
    "W1=tf.Variable([0.3],tf.float32)\r\n",
    "init=tf.compat.v1.global_variables_initializer()\r\n",
    "sess=tf.compat.v1.Session()\r\n",
    "sess.run(init)\r\n",
    "print(sess.run(W1))\r\n",
    "sess.close()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.3]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Y=b+W*X\r\n",
    "W=tf.Variable([3.0],tf.float32)\r\n",
    "b=tf.Variable([-0.9],tf.float32)\r\n",
    "X=tf.compat.v1.placeholder(tf.float32)\r\n",
    "linear_model=W*X+b\r\n",
    "init=tf.compat.v1.global_variables_initializer()\r\n",
    "sess=tf.compat.v1.Session()\r\n",
    "sess.run(init)\r\n",
    "print(sess.run(linear_model,{X:[1.0,2.0,3.0,4.0,5.0,6.0,7.0]}))\r\n",
    "sess.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 2.1  5.1  8.1 11.1 14.1 17.1 20.1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#cross entropy loss function for classification problems, and MSC for refgression problems... this is MSC ryt?\r\n",
    "Y=tf.compat.v1.placeholder(tf.float32)\r\n",
    "sq_delta=tf.square(linear_model-Y)\r\n",
    "loss=tf.reduce_sum(sq_delta)\r\n",
    "\r\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.01)\r\n",
    "train=optimizer.minimize(loss)\r\n",
    "\r\n",
    "init=tf.compat.v1.global_variables_initializer()\r\n",
    "sess=tf.compat.v1.Session()\r\n",
    "sess.run(init)\r\n",
    "\r\n",
    "for i in range(30):\r\n",
    "    sess.run(train, {X:[1,2,3,4],Y:[0,-1,-2,-3]})\r\n",
    "\r\n",
    "print(sess.run(W),sess.run(b))\r\n",
    "#cross entropy... loss= -sum(y*log(p))\r\n",
    "#p is probability obtained from softmax ...\r\n",
    "#y is the supervised learning outcome. \r\n",
    "#squared optimizer, dont need to worry about local minimas being a problem?\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.3075213] [-1.0359718]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}