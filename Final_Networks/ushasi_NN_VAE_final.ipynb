{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=200\n",
    "np.random.seed(1234567)\n",
    "#loading data and fitting follows:\n",
    "X_train=np.loadtxt('training_data/Xtrainloc_av_clean.csv',delimiter=',')\n",
    "Y_train=np.loadtxt('training_data/Ytrain_av_clean.csv',delimiter=',')\n",
    "#Xtrain=Xtrain[:2000]\n",
    "#X_train=np.transpose(X_train)\n",
    "print(X_train.shape,Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "X_train = np.array([np.convolve(X_train[i], kernel, mode='same') for i in range(len(X_train))])\n",
    "#X_test = [np.convolve(X_test[i], kernel, mode='same') for i in range(len(X_test))]\n",
    "#X_train=preprocessing.normalize(X_train)\n",
    "#scalar=preprocessing.StandardScaler()\n",
    "#scalar.fit(X_train)\n",
    "#X_train=scalar.transform(X_train)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_train, Y_train, test_size=0.1)\n",
    "print(Xtrain.shape,Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.array(Xtrain).shape)\n",
    "\n",
    "Xtrain=np.array(Xtrain).reshape(3220, img_size, 1)\n",
    "print(np.array(Xtrain).shape)\n",
    "#Xtrain=np.array(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a sampling function: returns a random sample from a mean and variance\n",
    "#that is input to it\n",
    "\n",
    "def sampling(mu_log_variance):\n",
    "    mu, log_variance = mu_log_variance\n",
    "    epsilon = keras.backend.random_normal(shape=keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
    "    random_sample = mu + keras.backend.exp(log_variance/2) * epsilon\n",
    "    return random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 100\n",
    "        reconstruction_loss = keras.backend.mean(keras.backend.square(y_true-y_predict), axis=[1, 2])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model defined here\n",
    "#leaky reLU has been added as a separate layer than define as an activation\n",
    "inp = keras.layers.Input(shape=(img_size, 1), name=\"encoder_input\")\n",
    "x1 = keras.layers.Conv1D(filters=1, kernel_size=3, padding=\"same\", strides=1,name=\"encoder_conv_1\", activation=\"tanh\")(inp)\n",
    "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_1\")(x1)\n",
    "#x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(x1)\n",
    "x1 = keras.layers.Conv1D(filters=16, kernel_size=3, padding=\"same\", strides=2, name=\"encoder_conv_2\",activation=\"tanh\")(x1)\n",
    "x1 = keras.layers.Conv1D(filters=16, kernel_size=3, padding=\"same\", strides=1, name=\"encoder_conv_2_sec\",activation=\"tanh\")(x1)\n",
    "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_2\")(x1)\n",
    "#x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(x1)\n",
    "x1 = keras.layers.Conv1D(filters=32, kernel_size=3, padding=\"same\", strides=1, name=\"encoder_conv_3\", activation=\"tanh\")(x1)\n",
    "x1 = keras.layers.Conv1D(filters=32, kernel_size=3, padding=\"same\", strides=1, name=\"encoder_conv_3_sec\", activation=\"tanh\")(x1)\n",
    "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_3\")(x1)\n",
    "#x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(x1)\n",
    "x1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", strides=1, name=\"encoder_conv_4\", activation=\"tanh\")(x1)\n",
    "x1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", strides=1, name=\"encoder_conv_4_sec\", activation=\"tanh\")(x1)\n",
    "#x1 = keras.layers.BatchNormalization(name=\"encoder_norm_4\")(x1)\n",
    "#x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(x1)\n",
    "#x1 = keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", strides=1, name=\"encoder_conv_5\", activation=\"tanh\")(x1)\n",
    "bp_lay_1 = keras.layers.BatchNormalization(name=\"encoder_norm_5\")(x1)\n",
    "#bp_lay_1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_4\")(x1)\n",
    "\n",
    "#flatten the layers in encoder\n",
    "shape_before_flatten = keras.backend.int_shape(bp_lay_1)[1:]\n",
    "aft_flat = keras.layers.Flatten(name=\"flat_1\")(bp_lay_1)\n",
    "\n",
    "latent_space_dim = 16\n",
    "#declare a mean and variance for the distribution\n",
    "encoder_mu = keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\",activity_regularizer=keras.regularizers.l1(10e-5))(aft_flat)\n",
    "encoder_log_variance = keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(aft_flat)\n",
    "encoder_op = keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
    "\n",
    "#decoder starts here\n",
    "x3 = keras.layers.Dense(units=np.prod(shape_before_flatten), activation=\"tanh\",name=\"decoder_dense_1\")(encoder_op)\n",
    "x3 = keras.layers.Reshape(target_shape=shape_before_flatten)(x3)\n",
    "\n",
    "#x3 = keras.layers.Conv1DTranspose(filters=128, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\", name=\"decoder_conv_tran_1\")(x3)\n",
    "#x3 = keras.layers.BatchNormalization(name=\"decoder_norm_1\")(x3)\n",
    "\n",
    "x3 = keras.layers.Conv1DTranspose(filters=64, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\", name=\"decoder_conv_tran_2\")(x3)\n",
    "x3 = keras.layers.Conv1DTranspose(filters=64, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\", name=\"decoder_conv_tran_2_sec\")(x3)\n",
    "x3 = keras.layers.BatchNormalization(name=\"decoder_norm_2\")(x3)\n",
    "#x3 = keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(x3)\n",
    "\n",
    "x3 = keras.layers.Conv1DTranspose(filters=32, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\",name=\"decoder_conv_tran_3\")(x3)\n",
    "x3 = keras.layers.Conv1DTranspose(filters=32, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\",name=\"decoder_conv_tran_3_sec\")(x3)\n",
    "x3 = keras.layers.BatchNormalization(name=\"decoder_norm_3\")(x3)\n",
    "#x3 = keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(x3)\n",
    "\n",
    "x3 = keras.layers.Conv1DTranspose(filters=16, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\", name=\"decoder_conv_tran_4\")(x3)\n",
    "x3 = keras.layers.Conv1DTranspose(filters=16, kernel_size=3, padding=\"same\", strides=2, activation=\"tanh\", name=\"decoder_conv_tran_4_sec\")(x3)\n",
    "x3 = keras.layers.BatchNormalization(name=\"decoder_norm_4\")(x3)\n",
    "#x3 = keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(x3)\n",
    "\n",
    "decoder_output = keras.layers.Conv1DTranspose(filters=1, kernel_size=3, padding=\"same\", strides=1,activation='tanh', name=\"decoder_op_layer\")(x3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.Model(inp,outputs=decoder_output, name=\"enc_dec\")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(loss=loss_func(encoder_mu, encoder_log_variance),optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "#history=vae.fit(Xtrain, Xtrain, epochs=20, batch_size=64 ,verbose=1, validation_split=0.3)\n",
    "loops=12\n",
    "autoencoder.fit(Xtrain, Xtrain, epochs=50, batch_size=64 ,verbose=1,shuffle=True, validation_split=0.2)\n",
    "''' \n",
    "temp=Xtrain\n",
    "for i in range(0,loops):\n",
    "    autoencoder.fit(temp, Xtrain, epochs=10, batch_size=64 ,verbose=1,shuffle=True, validation_split=0.2)\n",
    "    ypred=autoencoder.predict(Xtrain)\n",
    "    #autoencoder.fit(ypred,Xtrain,  epochs=5, batch_size=64 ,verbose=1,shuffle=True, validation_split=0.2)\n",
    "    temp=ypred'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred=autoencoder.predict(Xtrain)\n",
    "fig,ax=plt.subplots(10,2,figsize=(10,12))\n",
    "plt.style.use('seaborn-bright')\n",
    "plt.suptitle('sample reconstructions')\n",
    "ar=np.random.randint(0,len(Xtrain),size=10)\n",
    "ax[0][0].set_title('Original')\n",
    "ax[0][1].set_title('Generated')\n",
    "for i in range(0,10):\n",
    "    ax[i][0].plot(Xtrain[ar[i]],color='black',ls='None',marker='.')\n",
    "    ax[i][1].plot(Ypred[ar[i]],color='red',ls='None',marker='.')\n",
    "ax[4][0].set_xlabel('Phase')\n",
    "ax[4][1].set_xlabel('Phase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder_log_variance,encoder_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = keras.layers.concatenate([encoder_mu, encoder_log_variance],name='combine_layer')\n",
    "x3 = keras.layers.Dense(16, activation='tanh',name='class_lay_1')(x3)\n",
    "x3 = keras.layers.Dense(8, activation='tanh',name='class_lay_2')(x3)\n",
    "class_out = keras.layers.Dense(2, activation='sigmoid',name='class_op_layer')(x3)\n",
    "\n",
    "full_model=keras.models.Model(inp,class_out,name=\"classifier\")\n",
    "\n",
    "#print(full_model.get_weights()[0:9])\n",
    "#print(autoencoder.get_weights()[0:9])\n",
    "\n",
    "for layer in full_model.layers[0:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "full_model.summary()\n",
    "\n",
    "full_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),metrics='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "#history=vae.fit(Xtrain, Xtrain, epochs=20, batch_size=64 ,verbose=1, validation_split=0.3)\n",
    "history=full_model.fit(Xtrain, Ytrain, epochs=150, batch_size=64 ,verbose=1,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots(1,3,figsize=(10,5))\n",
    "plt.style.use(\"seaborn-bright\")\n",
    "\n",
    "ax[0].plot(history.history['class_op_layer_accuracy'], label='acc',color=\"black\")\n",
    "ax[0].plot(history.history['val_class_op_layer_accuracy'], label = 'val_acc',color=\"red\")\n",
    "ax[1].plot(history.history['class_op_layer_loss'], label='loss',color=\"black\")\n",
    "ax[1].plot(history.history['val_class_op_layer_loss'], label = 'val_loss',color=\"red\")\n",
    "ax[2].plot(history.history['decoder_op_layer_loss'], label='loss',color=\"black\")\n",
    "ax[2].plot(history.history['val_decoder_op_layer_loss'], label = 'val_loss',color=\"red\")\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[2].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[0].set_title('Classification Accuracy')\n",
    "ax[1].set_title('Classification Loss')\n",
    "ax[2].set_title('Decoder Loss')\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[1].legend(loc='lower right')\n",
    "ax[2].legend(loc='lower right')\n",
    "#plt.savefig('VAE_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Xtest=np.array(Xtrain).reshape(1138, 7936, 1)\n",
    "#Xtest=preprocessing.normalize(Xtest)\n",
    "Xtest=np.array(Xtest).reshape(358, 200, 1)\n",
    "test_loss,test_acc = full_model.evaluate(np.array(Xtest),np.array(Ytest))\n",
    "print('Test accuracy:', test_acc)\n",
    "Y_pred2=full_model.predict(np.array(Xtest))\n",
    "Ypred=np.argmax(Y_pred2, axis=1)\n",
    "Ytest_new=np.argmax(Ytest,axis=1)\n",
    "cm = confusion_matrix(Ytest_new, Ypred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
