{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's my attempt at writing a different NN to tackle my problem... this is an inception network. lets see if it works\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some errors in this class thing so we'll see later....\n",
    "class InceptionTime(keras.layers.Layer):\n",
    "    def __init__(self, num_filters=32, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_filters=num_filters\n",
    "        self.activation=keras.activations.get(activation)\n",
    "        #self.conv1=keras.layers.Conv1D(filters=8, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")\n",
    "        #self.conv1_2=keras.layers.Conv1D(filters=8, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")\n",
    "        #self.conv10=keras.layers.Conv1D(filters=8, kernel_size=10, padding=\"same\", strides=1, activation=\"tanh\")\n",
    "        #self.conv20=keras.layers.Conv1D(filters=8, kernel_size=20, padding=\"same\", strides=1, activation=\"tanh\")\n",
    "        #self.conv40=keras.layers.Conv1D(filters=8, kernel_size=40, padding=\"same\", strides=1, activation=\"tanh\")\n",
    "\n",
    "    def call(self, inputs,training=None):\n",
    "        bN = keras.layers.Conv1D(filters=self.num_filters, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(inputs)\n",
    "        mP = keras.layers.MaxPool1D(3,strides=1 ,data_format='channels_last',padding='same')(inputs)\n",
    "        z1 = keras.layers.Conv1D(filters=self.num_filters, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\")(bN)\n",
    "        z2 = keras.layers.Conv1D(filters=self.num_filters, kernel_size=7, padding=\"same\", strides=1, activation=\"tanh\")(bN)\n",
    "        z3 = keras.layers.Conv1D(filters=self.num_filters, kernel_size=11, padding=\"same\", strides=1, activation=\"tanh\")(bN)\n",
    "        z4 = keras.layers.Conv1D(filters=self.num_filters, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(mP)\n",
    "        z = keras.layers.Concatenate(axis=2)([z1,z2,z3,z4])\n",
    "        z = keras.layers.BatchNormalization()(z)\n",
    "        return self.activation(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = keras.layers.Input(shape=(IMG_SIZE,1),name='Input')\n",
    "x = keras.layers.Reshape((IMG_SIZE, 1), input_shape=(IMG_SIZE,),name='reshape_1')(ip)\n",
    "x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", strides=1, activation=\"tanh\")(x)\n",
    "\n",
    "y = keras.layers.Conv1D(filters=32, kernel_size=1, padding=\"same\", strides=2, activation=\"tanh\",name='bypass')(x)\n",
    "#y = keras.layers.Conv1D(filters=32, kernel_size=1, padding=\"same\", strides=2, activation=\"relu\",name='bypass2')(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "\n",
    "bN1 = keras.layers.Conv1D(filters=8, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(x)\n",
    "bN2 = keras.layers.Conv1D(filters=8, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(x)\n",
    "bN3 = keras.layers.Conv1D(filters=8, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(x)\n",
    "mP = keras.layers.MaxPool1D(3,strides=1 ,data_format='channels_last',padding='same')(x)\n",
    "z1 = keras.layers.Conv1D(filters=8, kernel_size=5, padding=\"same\", strides=1, activation=\"tanh\")(bN1)\n",
    "z2 = keras.layers.Conv1D(filters=8, kernel_size=15, padding=\"same\", strides=1, activation=\"tanh\")(bN2)\n",
    "z3 = keras.layers.Conv1D(filters=8, kernel_size=35, padding=\"same\", strides=1, activation=\"tanh\")(bN3)\n",
    "z4 = keras.layers.Conv1D(filters=4, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(mP)\n",
    "z = keras.layers.Concatenate(axis=2)([z1,z2,z3,z4])\n",
    "z = keras.layers.BatchNormalization()(z)\n",
    "\n",
    "z  = keras.layers.AveragePooling1D(3,strides=1,padding='same')(z)\n",
    "\n",
    "bNI1 = keras.layers.Conv1D(filters=16, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(z)\n",
    "bNI2 = keras.layers.Conv1D(filters=16, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(z)\n",
    "bNI3 = keras.layers.Conv1D(filters=16, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(z)\n",
    "mPI = keras.layers.MaxPool1D(3,strides=1 ,data_format='channels_last',padding='same')(z)\n",
    "zI1 = keras.layers.Conv1D(filters=16, kernel_size=5, padding=\"same\", strides=1, activation=\"tanh\")(bNI1)\n",
    "zI2 = keras.layers.Conv1D(filters=16, kernel_size=15, padding=\"same\", strides=1, activation=\"tanh\")(bNI2)\n",
    "zI3 = keras.layers.Conv1D(filters=16, kernel_size=35, padding=\"same\", strides=1, activation=\"tanh\")(bNI3)\n",
    "zI4 = keras.layers.Conv1D(filters=8, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(mPI)\n",
    "zI = keras.layers.Concatenate(axis=2)([zI1,zI2,zI3,zI4])\n",
    "zI = keras.layers.BatchNormalization()(zI)\n",
    "\n",
    "zI  = keras.layers.AveragePooling1D(3,strides=2,padding='same')(zI)\n",
    "\n",
    "bNII1 = keras.layers.Conv1D(filters=32, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(zI)\n",
    "bNII2 = keras.layers.Conv1D(filters=32, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(zI)\n",
    "bNII3 = keras.layers.Conv1D(filters=32, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(zI)\n",
    "mPII = keras.layers.MaxPool1D(3,strides=1 ,data_format='channels_last',padding='same')(zI)\n",
    "z1II = keras.layers.Conv1D(filters=32, kernel_size=5, padding=\"same\", strides=1, activation=\"tanh\")(bNII1)\n",
    "z2II = keras.layers.Conv1D(filters=32, kernel_size=15, padding=\"same\", strides=1, activation=\"tanh\")(bNII2)\n",
    "z3II = keras.layers.Conv1D(filters=32, kernel_size=35, padding=\"same\", strides=1, activation=\"tanh\")(bNII3)\n",
    "z4II = keras.layers.Conv1D(filters=16, kernel_size=1, padding=\"same\", strides=1, activation=\"tanh\")(mPII)\n",
    "zII = keras.layers.Concatenate(axis=2,name='bypassed_here')([z1II,z2II,z3II,z4II,y])\n",
    "zII = keras.layers.BatchNormalization()(zII)\n",
    "\n",
    "zII  = keras.layers.AveragePooling1D(3,strides=2,padding='same')(zII)\n",
    "\n",
    "zII = keras.layers.Flatten()(zII)\n",
    "zII = keras.layers.Dense(128,activation='relu')(zII)\n",
    "zII = keras.layers.Dense(64,activation='relu')(zII)\n",
    "zII =  keras.layers.Dense(1,activation='relu')(zII)\n",
    "zII =  keras.layers.Dense(2,activation='softmax')(zII)\n",
    "\n",
    "NN = keras.Model(inputs=ip, outputs=zII ,name='Convolutional_NN')\n",
    "NN.summary()\n",
    "\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.00005,decay_steps=500,decay_rate=0.5)\n",
    "NN.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234567)\n",
    "X_train=np.loadtxt('training_data/Xtrain_av_raw200_2_2d0_v2.csv',delimiter=',')\n",
    "Y_train=np.loadtxt('training_data/Ytrain_av_raw200_2_2d0_v2.csv',delimiter=',')\n",
    "print(X_train.shape,Y_train.shape)\n",
    "kernel_size = 3\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "X_train = np.array([np.convolve(X_train[i], kernel, mode='same') for i in range(len(X_train))])\n",
    "#X_train=preprocessing.normalize(X_train)\n",
    "#X_train=-X_train\n",
    "#scalar=preprocessing.StandardScaler()\n",
    "#scalar.fit(X_train)\n",
    "#X_train=scalar.transform(X_train)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "print(Xtrain.shape,Xtest.shape)\n",
    "\n",
    "vararr=np.random.randint(0,len(Xtrain),size=10)\n",
    "fig,ax=plt.subplots(10,1,figsize=(10,20))\n",
    "for i in range(0,10):\n",
    "    ax[i].plot(Xtrain[vararr[i]])\n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "#history=convNN.fit([np.array(Xtrain),np.array(Xtrainl)],np.array(Ytrain), batch_size=64, epochs=40, verbose=VERBOSE, validation_split=0.12,callbacks=[es_callback])\n",
    "history=NN.fit(np.array(Xtrain),np.array(Ytrain), batch_size=64, epochs=20  , verbose=1 ,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('macc_SandN_raw500.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current verdict? it does quite well on the 2d5 thing... much better than i imagined. Not so much for the 2d0 thing... but maybe that lightcurve needs \n",
    "#rebinning... and  i havent fine tuned it or anything yet.\n",
    "test_loss, test_acc = NN.evaluate(np.array(Xtest), np.array(Ytest))\n",
    "print('Test accuracy:', test_acc)\n",
    "Ypred_raw=NN.predict(np.array(Xtest))\n",
    "Ypred=np.argmax(Ypred_raw, axis=1)\n",
    "Ytest_new=np.argmax(Ytest,axis=1)\n",
    "cm = confusion_matrix(Ytest_new, Ypred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
