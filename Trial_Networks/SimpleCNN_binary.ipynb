{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "import pandas as pd\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import GetLightcurves as gc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#network and training parameters:\n",
                "BATCH_SIZE = 128\n",
                "VERBOSE = 1 #no idea what this is but lets see...\n",
                "VAL_SPLIT = 0.2  #how much of sample is reserved for validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Xtrain=np.loadtxt('training_data/Xtrain_no_npl.csv',delimiter=',')\n",
                "Ytrain=np.loadtxt('training_data/Ytrain_no_npl.csv',delimiter=',')\n",
                "Xtest=np.loadtxt('training_data/Xtest_no_npl.csv',delimiter=',')\n",
                "Ytest=np.loadtxt('training_data/Ytest_no_npl.csv',delimiter=',')\n",
                "print(Xtrain.shape,Ytrain.shape,Xtest.shape,Ytest.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Xtrain2=np.loadtxt('training_data/Xtrain_no_fps.csv',delimiter=',')\n",
                "Ytrain2=np.loadtxt('training_data/Ytrain_no_fps.csv',delimiter=',')\n",
                "Xtest2=np.loadtxt('training_data/Xtest_no_fps.csv',delimiter=',')\n",
                "Ytest2=np.loadtxt('training_data/Ytest_no_fps.csv',delimiter=',')\n",
                "print(Xtrain2.shape,Ytrain2.shape,Xtest2.shape,Ytest2.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Xtrainl,Xtrain,Ytrain,IDtrain = gc.read_tfr_record('../../training_data/total_ts_av_train',['local','global','label','id'],\n",
                "    ['ar','ar','ar','b'],[tf.float32,tf.float32,tf.bool, tf.string])\n",
                "Xtestl,Xtest,Ytest, IDtest = gc.read_tfr_record('../../training_data/total_ts_av_test',['local','global','label','id'],\n",
                "    ['ar','ar','ar','b'],[tf.float32,tf.float32,tf.bool, tf.string])\n",
                "\n",
                "Ytrain = np.asarray(Ytrain, dtype='float32')\n",
                "Ytest = np.asarray(Ytest, dtype='float32')\n",
                "Xtrain = np.asarray(Xtrain, dtype='float32')\n",
                "Xtrainl = np.asarray(Xtrainl, dtype='float32')\n",
                "Xtest = np.asarray(Xtest, dtype='float32')\n",
                "Xtestl = np.asarray(Xtestl, dtype='float32')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Xtrainl_n = [(row - np.median(row))/(np.median(row)-min(row)) for row in Xtrainl]\n",
                "#Xtestl_n = [(row - np.median(row))/(np.median(row)-min(row)) for row in Xtestl]\n",
                "Xtrainl_n = [np.tanh(100*row) for row in Xtrainl]\n",
                "Xtestl_n = [np.tanh(100*row) for row in Xtestl]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#got the training set ... now write the neural net\n",
                "#buid the model\n",
                "#SGD stochastic gradient descent... \n",
                "DROPOUT=0.3\n",
                "IP=4000\n",
                "TEST=200\n",
                "np.random.seed(11223)\n",
                "\n",
                "arr=np.arange(0,IP,1)\n",
                "np.random.shuffle(arr)\n",
                "Xtrain=[Xtrain[i] for i in arr]\n",
                "Ytrain=[Ytrain[i] for i in arr]\n",
                "\n",
                "arr=np.arange(0,TEST,1)\n",
                "np.random.shuffle(arr)\n",
                "Xtest=[Xtest[i] for i in arr]\n",
                "Ytest=[Ytest[i] for i in arr]\n",
                "\n",
                "#kernel_size = 5\n",
                "#kernel = np.ones(kernel_size) / kernel_size\n",
                "#Xtrain = [np.convolve(Xtrain[i], kernel, mode='same') for i in range(IP)]\n",
                "#Xtest = [np.convolve(Xtest[i], kernel, mode='same') for i in range(TEST)]\n",
                "#Xtrain_new=np.array(Xtrain).reshape(5700,500,4)\n",
                "#print(Xtrain_new.shape)\n",
                "\n",
                "ip = keras.layers.Input(shape=(2000,),name='Input')\n",
                "x=keras.layers.Dense(256,name='dense_layer_1',activation='relu')(ip)\n",
                "x=keras.layers.Dropout(0.2)(x)\n",
                "x=keras.layers.Dense(128,name='dense_layer_2',activation='relu')(ip)\n",
                "x=keras.layers.Dropout(0.2)(x)\n",
                "x=keras.layers.Dense(64,name='dense_layer_3',activation='relu')(x)\n",
                "x=keras.layers.Dropout(0.2)(x)\n",
                "x=keras.layers.Dense(32,name='dense_layer_4',activation='relu')(x)\n",
                "x=keras.layers.Dropout(0.2)(x)\n",
                "op=keras.layers.Dense(2,name='dense_layer_5',activation='softmax')(x)\n",
                "convNN = keras.Model(inputs=ip, outputs=op,name='Convolutional_NN')\n",
                "#add hidden layers\n",
                "#conv_ip = keras.layers.Input(shape=(2000,),name='Input')\n",
                "#x=keras.layers.Reshape((2000, 1), input_shape=(2000,),name='reshape_1')(conv_ip)\n",
                "#x=keras.layers.BatchNormalization()(x)\n",
                "#x=keras.layers.Conv1D(16,kernel_size=5,strides=2,activation='relu',name='conv16_5')(x) \n",
                "#x=keras.layers.Conv1D(16,kernel_size=5,strides=2,activation='relu',name='second_conv16_5')(x)\n",
                "#x=keras.layers.MaxPool1D(3,strides=3,data_format='channels_last',name='maxpool_1')(x)\n",
                "#x=keras.layers.Conv1D(32,kernel_size=5,strides=1,activation='relu',name='first_conv32_5')(checkf)\n",
                "#x=keras.layers.Conv1D(32,kernel_size=5,strides=1,activation='relu',name='second_conv32_5')(x)\n",
                "#x=keras.layers.MaxPool1D(3,strides=3,data_format='channels_last',name='maxpool_2')(x)\n",
                "#x=keras.layers.Conv1D(64,kernel_size=5,strides=1,activation='relu',name='conv64_5')(x)\n",
                "#x=keras.layers.Conv1D(64,kernel_size=5,strides=1,activation='relu',name='conv64_5_2')(x)\n",
                "#x=keras.layers.MaxPool1D(3,strides=3,data_format='channels_last',name='maxpool_3')(x)\n",
                "#x=keras.layers.Flatten(name='flat_1')(x)\n",
                "#x=keras.layers.Dense(16,name='dense_layer_1',activation='relu')(x)\n",
                "#conv_op=keras.layers.Dense(2,name='dense_layer_2',activation='softmax')(x)\n",
                "\n",
                "\n",
                "#convNN = keras.Model(inputs=conv_ip, outputs=conv_op,name='Convolutional_NN')\n",
                "\n",
                "#featuresNN = keras.Model(inputs=conv_ip, outputs=checkf)\n",
                "\n",
                "convNN.summary()\n",
                "convNN.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nums=np.random.randint(0,len(Xtrain), 30)\n",
                "fig, ax = plt.subplots(5,5,figsize = (15,15))\n",
                "i=0\n",
                "j=0\n",
                "for el in nums:\n",
                "    ax[i][j].plot(Xtrainl_n[el])\n",
                "    i+=1\n",
                "    if(i==5):\n",
                "        i=0\n",
                "        j+=1\n",
                "    if(j==5): break\n",
                "plt.show"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "DROPOUT=0.3\n",
                "IP=4000\n",
                "TEST=200\n",
                "np.random.seed(11223)\n",
                "\n",
                "#add hidden layers\n",
                "conv_ip2 = keras.layers.Input(shape=(200,),name='Input')\n",
                "x2=keras.layers.Reshape((200, 1), input_shape=(200,),name='reshape_1')(conv_ip2)\n",
                "x2=keras.layers.BatchNormalization()(x2)\n",
                "x2=keras.layers.Conv1D(16,kernel_size=5,strides=2,activation='tanh',name='conv16_5')(x2) \n",
                "x2=keras.layers.Conv1D(16,kernel_size=5,strides=2,activation='tanh',name='second_conv16_5')(x2)\n",
                "checkf2=keras.layers.MaxPool1D(3,strides=1,data_format='channels_last',name='maxpool_1')(x2)\n",
                "x2=keras.layers.Conv1D(32,kernel_size=5,strides=1,activation='tanh',name='first_conv32_5')(checkf2)\n",
                "x2=keras.layers.Conv1D(32,kernel_size=5,strides=1,activation='tanh',name='second_conv32_5')(x2)\n",
                "x2=keras.layers.MaxPool1D(3,strides=1,data_format='channels_last',name='maxpool_2')(x2)\n",
                "x2=keras.layers.Conv1D(64,kernel_size=5,strides=1,activation='tanh',name='conv64_5')(x2)\n",
                "x2=keras.layers.Conv1D(64,kernel_size=5,strides=1,activation='tanh',name='conv64_5_2')(x2)\n",
                "x2=keras.layers.MaxPool1D(3,strides=1,data_format='channels_last',name='maxpool_3')(x2)\n",
                "x2=keras.layers.Flatten(name='flat_1')(x2)\n",
                "x2=keras.layers.Dense(64,name='dense_layer_1',activation='relu')(x2)\n",
                "x2=keras.layers.Dense(64,name='dense_layer_2',activation='relu')(x2)\n",
                "x2=keras.layers.Dense(64,name='dense_layer_3',activation='relu')(x2)\n",
                "conv_op2=keras.layers.Dense(2,name='dense_layer_4',activation='softmax')(x2)\n",
                "\n",
                "\n",
                "convNN2 = keras.Model(inputs=conv_ip2, outputs=conv_op2,name='Convolutional_NN')\n",
                "\n",
                "featuresNN2 = keras.Model(inputs=conv_ip2, outputs=checkf2)\n",
                "\n",
                "convNN2.summary()\n",
                "convNN2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00005), loss='categorical_crossentropy',metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
                "history=convNN2.fit(np.asarray(Xtrainl_n),np.asarray(Ytrain), batch_size=256, epochs=70, verbose=VERBOSE, validation_split=VAL_SPLIT, callbacks=[es_callback])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "''''es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
                "history2=convNN2.fit(np.array(Xtrain2),np.array(Ytrain2), batch_size=64, epochs=100, verbose=VERBOSE, validation_split=VAL_SPLIT, callbacks=[es_callback])'''\n",
                "print(\" \")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(history.history['loss'])\n",
                "plt.plot(history.history['val_loss'])\n",
                "#plt.plot(history.history['loss'])\n",
                "#plt.plot(history.history['val_loss'])\n",
                "plt.title('model loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['train_1', 'test_1'], loc='upper left')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(history.history['accuracy'])\n",
                "plt.plot(history.history['val_accuracy'])\n",
                "#plt.plot(history2.history['accuracy'])\n",
                "#plt.plot(history2.history['val_accuracy'])\n",
                "plt.title('model accuracy')\n",
                "plt.ylabel('accuracy')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['train_1', 'test_1','train_2', 'test_2'], loc='upper left')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_loss, test_acc = convNN2.evaluate(np.array(Xtestl_n), np.array(Ytest))\n",
                "print('Test accuracy:', test_acc)\n",
                "Ypred_raw=convNN2.predict(np.array(Xtestl_n))\n",
                "Ypred=np.argmax(Ypred_raw, axis=1)\n",
                "Ytest_new=np.argmax(Ytest,axis=1)\n",
                "cm = confusion_matrix(Ytest_new, Ypred)\n",
                "print(cm)\n",
                "\n",
                "'''test_loss2, test_acc2 = convNN2.evaluate(np.array(Xtest2), np.array(Ytest2))\n",
                "print('Test accuracy:', test_acc2)\n",
                "Ypred_raw2=convNN2.predict(np.array(Xtest2))\n",
                "Ypred2=np.argmax(Ypred_raw2, axis=1)\n",
                "Ytest_new2=np.argmax(Ytest2,axis=1)\n",
                "cm2 = confusion_matrix(Ytest_new2, Ypred2)\n",
                "print(cm2)'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
        },
        "kernelspec": {
            "display_name": "Python 3.9.5 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
