{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "import pandas as pd\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "from sklearn.model_selection import train_test_split\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#network and training parameters:\n",
                "EPOCHS = 100 #how many iterations we run the training set\n",
                "BATCH_SIZE = 128\n",
                "VERBOSE = 1 #no idea what this is but lets see...\n",
                "NB_CLASSES = 10 #10 digits\n",
                "N_HIDDEN = 1000 #number of nodes in hidden layer\n",
                "VAL_SPLIT = 0.2  #how much of sample is reserved for validation\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "X_train=np.loadtxt('training_data/Xtrain_av_clean.csv',delimiter=',')\n",
                "Y_train=np.loadtxt('training_data/Ytrain_av_clean.csv',delimiter=',')\n",
                "X_trainloc=np.loadtxt('training_data/Xtrainloc_av_clean.csv',delimiter=',')\n",
                "#X_train=preprocessing.normalize(X_train)\n",
                "#X_train=X_train[:,150:350]\n",
                "#scalar=preprocessing.StandardScaler()\n",
                "#scalar.fit(X_train)\n",
                "#X_train=scalar.transform(X_train)\n",
                "#X_train=X_train\n",
                "\n",
                "Xtrain, Xtest, Ytrain, Ytest, Xtrainl, Xtestl = train_test_split(X_train, Y_train, X_trainloc, test_size=0.2)\n",
                "print(Xtrain.shape,Ytrain.shape,Xtest.shape,Ytest.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#got the training set ... now write the neural net\n",
                "#buid the model\n",
                "#SGD stochastic gradient descent... \n",
                "IMGG=2000\n",
                "IMGL=200\n",
                "\n",
                "#add hidden layers\n",
                "ip = keras.layers.Input(shape=(IMGG,),name='Input')\n",
                "ipl = keras.layers.Input(shape=(IMGL,),name='Inputl')\n",
                "x = keras.layers.BatchNormalization()(ip)\n",
                "x = keras.layers.Dense(512,name='dense_layer',activation='tanh')(x)\n",
                "x = keras.layers.Dense(512,name='dense_layer_2',activation='tanh')(x)\n",
                "x = keras.layers.Dense(128,name='dense_layer_2b',activation='tanh')(x)\n",
                "x = keras.layers.Dense(128,name='dense_layer_2c',activation='relu')(x)\n",
                "x = keras.layers.Dense(64,name='dense_layer_3',activation='relu')(x)\n",
                "\n",
                "xl = keras.layers.BatchNormalization()(ipl)\n",
                "xl = keras.layers.Dense(128,name='Ldense_layer',activation='tanh')(xl)\n",
                "xl = keras.layers.Dense(128,name='Ldense_layer_2',activation='tanh')(xl)\n",
                "xl = keras.layers.Dense(64,name='Ldense_layer_2b',activation='tanh')(xl)\n",
                "xl = keras.layers.Dense(64,name='Ldense_layer_2c',activation='relu')(xl)\n",
                "xl = keras.layers.Dense(32,name='Ldense_layer_3',activation='relu')(xl)\n",
                "\n",
                "x2 = keras.layers.Concatenate()([xl,x])\n",
                "x2 = keras.layers.Dense(16,name='classify1',activation='relu')(x2)\n",
                "x2 = keras.layers.Dense(1,name='classify2',activation='relu')(x2)\n",
                "x2 = keras.layers.Dense(2,name='classify3',activation='softmax')(x2)\n",
                "DenseNN = keras.Model(inputs=[ip,ipl], outputs=x2,name='Convolutional_NN')\n",
                "DenseNN.summary()\n",
                "DenseNN.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00005), loss='categorical_crossentropy',metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
                "history=DenseNN.fit([np.asarray(Xtrain),np.asarray(Xtrainl)],np.asarray(Ytrain), batch_size=64, epochs=100,\n",
                "     verbose=1, validation_split=0.2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(history.history['loss'])\n",
                "plt.plot(history.history['val_loss'])\n",
                "plt.title('model loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['train', 'test'], loc='upper left')\n",
                "#plt.savefig('present_fullyconnected_loss_glob.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(history.history['accuracy'])\n",
                "plt.plot(history.history['val_accuracy'])\n",
                "plt.title('model accuracy')\n",
                "plt.ylabel('accuracy')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['train', 'test'], loc='upper left')\n",
                "plt.savefig('present_fullyconnected_acc_global.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_loss, test_acc = DenseNN.evaluate(np.array(Xtest), np.array(Ytest))\n",
                "print('Test accuracy:', test_acc)\n",
                "Ypred_raw=DenseNN.predict(np.array(Xtest))\n",
                "Ypred=np.argmax(Ypred_raw, axis=1)\n",
                "Ytest_new=np.argmax(Ytest,axis=1)\n",
                "cm = confusion_matrix(Ytest_new, Ypred)\n",
                "print(cm)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
