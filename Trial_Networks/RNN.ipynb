{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=200\n",
    "np.random.seed(1234567)\n",
    "#loading data and fitting follows:\n",
    "X_train=np.loadtxt('training_data/Xtrain_av_raw200_2_2d0_v2.csv',delimiter=',')\n",
    "Y_train=np.loadtxt('training_data/Ytrain_av_raw200_2_2d0_v2.csv',delimiter=',')\n",
    "X_extra=np.loadtxt('training_data/Xextra_av_raw200_2_2d0_v2.csv',delimiter=',')\n",
    "#Xtrain=Xtrain[:2000]\n",
    "#X_train=np.transpose(X_train)\n",
    "print(X_train.shape,Y_train.shape,X_extra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "X_train = np.array([np.convolve(X_train[i], kernel, mode='same') for i in range(len(X_train))])\n",
    "#X_test = [np.convolve(Xtest[i], kernel, mode='same') for i in range(len(Xtest))]\n",
    "Xtrain, Xtest, Ytrain, Ytest, Xextra_tr, Xextra_tst = train_test_split(X_train, Y_train, X_extra, test_size=0.1)\n",
    "print(Xtrain.shape,Xtest.shape,Xextra_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt=[]\n",
    "for el in Xtrain:\n",
    "    med=np.median(el)\n",
    "    min=el[np.argmin(el)]\n",
    "    std=np.std(el)\n",
    "    temp=(el-med)/(med-min)\n",
    "    clean=[x for x in temp if x > med-std]\n",
    "    wt.append(1/np.power(np.std(clean),0.25))\n",
    "\n",
    "norm = np.linalg.norm(np.array(wt))\n",
    "wt= 1000*(np.array(wt)/norm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test run a RNN  which i dont understand much about, but im hopeful\n",
    "#Xtrain=np.transpose(Xtrain)\n",
    "inp = keras.layers.Input(shape=(200,), name=\"rnn_input\")\n",
    "x=keras.layers.Reshape(target_shape=(200,1))(inp)\n",
    "x=keras.layers.GRU(20, return_sequences=True,name=\"GRU_lay_1\")(x)\n",
    "#model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "#x=keras.layers.RepeatVector(200)(x)\n",
    "bp=keras.layers.GRU(40, return_sequences=True,name=\"GRU_lay_2\")(x)\n",
    "#shape_before_flatten = keras.backend.int_shape(bp)[1:]\n",
    "x=keras.layers.GRU(60,return_sequences=True,name=\"GRU_lay_3\")(x)\n",
    "bp=keras.layers.TimeDistributed(keras.layers.Dense(1),name='op1')(bp)\n",
    "#bp=keras.layers.Flatten()(bp)\n",
    "\n",
    "#op=keras.layers.Dense(32,activation='tanh',name='latentspace')(bp)\n",
    "\n",
    "#x1=keras.layers.Dense(np.prod(shape_before_flatten),name='dec_1',activation='tanh')(op)\n",
    "#x1=keras.layers.RepeatVector(200)(op)\n",
    "#x=keras.layers.Dense(32,activation='relu')(x)\n",
    "#x=keras.layers.Dense(2,activation='relu',name='op2')(x)\n",
    "#x1=keras.layers.Reshape(target_shape=shape_before_flatten,name='reshape')(x1)\n",
    "#x1=keras.layers.LSTM(40, return_sequences=True,name=\"GRU_layD_2\")(x1)\n",
    "#x1=keras.layers.LSTM(20, return_sequences=True,name=\"GRU_layD_1\")(x1)\n",
    "#x1=keras.layers.TimeDistributed(keras.layers.Dense(1),name='op2')(x1)\n",
    "\n",
    "rnn = keras.models.Model(inp, bp, name=\"rnn\")\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " rnn.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=rnn.fit(Xtrain, Xtrain, epochs=20,batch_size=64 , verbose=1,validation_split=0.2,shuffle=True,sample_weight=wt  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred=rnn.predict(Xtest)\n",
    "fig,ax=plt.subplots(10,1,figsize=(10,20))\n",
    "inc=500\n",
    "for i in range(10):\n",
    "    ax[i].plot(Ypred[i+inc,:,0])\n",
    "    ax[i].plot(Xtest[i+inc,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ex = keras.layers.Input(shape=(3,), name=\"encoder_input\")\n",
    "x3 = keras.layers.concatenate([op, inp_ex],name='combine_layer')\n",
    "x3 = keras.layers.Dense(16, activation='tanh',name='class_lay_1')(op)\n",
    "x3 = keras.layers.Dense(8, activation='relu',name='class_lay_2')(x3)\n",
    "x3 = keras.layers.Dense(1, activation='relu',name='class_lay_3')(x3)\n",
    "class_out = keras.layers.Dense(2, activation='softmax',name='class_op_layer')(x3)\n",
    "\n",
    "full_model=keras.models.Model([inp,inp_ex],class_out,name=\"classifier\")\n",
    "\n",
    "for layer in full_model.layers[0:6]:\n",
    "    layer.trainable = False\n",
    "\n",
    "full_model.summary()\n",
    "\n",
    "full_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "#history=vae.fit(Xtrain, Xtrain, epochs=20, batch_size=64 ,verbose=1, validation_split=0.3)\n",
    "history=full_model.fit([Xtrain,Xextra_tr], Ytrain, epochs=70, batch_size=64 ,verbose=1,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#Xtest=np.array(Xtrain).reshape(1138, 7936, 1)\n",
    "#Xtest=preprocessing.normalize(Xtest)\n",
    "#Xtest=np.array(Xtest).reshape(358, 2000, 1)\n",
    "test_loss, test_acc =  full_model.evaluate([np.array(Xtest),np.array(Xextra_tst)],np.array(Ytest))\n",
    "print('Test accuracy:', test_acc)\n",
    "Y_pred = full_model.predict([np.array(Xtest),Xextra_tst])\n",
    "Ypred=np.argmax(Y_pred, axis=1)\n",
    "Ytest_new=np.argmax(Ytest,axis=1)\n",
    "cm = confusion_matrix(Ytest_new, Ypred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
