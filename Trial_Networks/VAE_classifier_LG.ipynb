{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import numpy as np\r\n",
                "import tensorflow as tf\r\n",
                "from tensorflow import keras\r\n",
                "from tensorflow.keras import layers"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "\r\n",
                "#loading data and fitting follows:\r\n",
                "Xtrain=[]\r\n",
                "Ytrain=[]\r\n",
                "np.random.seed(1234567)\r\n",
                "Xtrain=np.loadtxt('training_data/Xtrain_big.csv',delimiter=',')\r\n",
                "Ytrain=np.loadtxt('training_data/YtrainR_big.csv',delimiter=',')\r\n",
                "#Xtrain=Xtrain[:12000]\r\n",
                "#Xtrain=np.transpose(Xtrain)\r\n",
                "print(Xtrain.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(4500, 2000)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "img_size=2000\r\n",
                "#Xtrain_N=[]\r\n",
                "#[Xtrain_N.append(Xtrain[i]/np.abs(Xtrain[i][np.argmin(Xtrain[i])])) for i in range(0,3231)]\r\n",
                "#Xtrain=np.array(Xtrain_N).reshape(3231,12000,1)\r\n",
                "arr=np.arange(0,4500,1)\r\n",
                "np.random.shuffle(arr)\r\n",
                "Xtrain=np.array([Xtrain[i] for i in arr])\r\n",
                "Ytrain=np.array([Ytrain[i] for i in arr])\r\n",
                "#Xtrain=Xtrain[0:1500]\r\n",
                "#Ytrain=Ytrain[0:1500]\r\n",
                "print(Xtrain.shape)\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(4500, 2000)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "def sampling(mu_log_variance):\r\n",
                "    mu, log_variance = mu_log_variance\r\n",
                "    epsilon = keras.backend.random_normal(shape=keras.backend.shape(mu), mean=0.0, stddev=1.0)\r\n",
                "    random_sample = mu + keras.backend.exp(log_variance/2) * epsilon\r\n",
                "    return random_sample"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "source": [
                "#model defined here\r\n",
                "inp = keras.layers.Input(shape=(img_size, 1), name=\"encoder_input\")\r\n",
                "#leaky reLU has been added as a separate layer than define as an activation\r\n",
                "x1 = keras.layers.Conv1D(filters=1, kernel_size=5, padding=\"same\", strides=1,name=\"encoder_conv_1\")(inp)\r\n",
                "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_1\")(x1)\r\n",
                "x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(x1)\r\n",
                "\r\n",
                "x1 = keras.layers.Conv1D(filters=16, kernel_size=5, padding=\"same\", strides=1, name=\"encoder_conv_2\")(x1)\r\n",
                "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_2\")(x1)\r\n",
                "x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(x1)\r\n",
                "\r\n",
                "x1 = keras.layers.Conv1D(filters=32, kernel_size=5, padding=\"same\", strides=1, name=\"encoder_conv_3\")(x1)\r\n",
                "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_3\")(x1)\r\n",
                "bp_lay_1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(x1)\r\n",
                "#flatten the layers in encoder\r\n",
                "shape_before_flatten = keras.backend.int_shape(bp_lay_1)[1:]\r\n",
                "x2 = keras.layers.Flatten(name=\"flat_1\")(bp_lay_1)\r\n",
                "\r\n",
                "latent_space_dim = 8\r\n",
                "#declare a mean and variance for the distribution\r\n",
                "encoder_mu = keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(x2)\r\n",
                "encoder_log_variance = keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(x2)\r\n",
                "encoder_op = keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\r\n",
                "\r\n",
                "encoder = keras.models.Model(inp, encoder_op, name=\"encoder_model\")\r\n",
                "encoder.summary()\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Model: \"encoder_model\"\n",
                        "__________________________________________________________________________________________________\n",
                        "Layer (type)                    Output Shape         Param #     Connected to                     \n",
                        "==================================================================================================\n",
                        "encoder_input (InputLayer)      [(None, 2000, 1)]    0                                            \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_conv_1 (Conv1D)         (None, 2000, 1)      6           encoder_input[0][0]              \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_norm_1 (BatchNormalizat (None, 2000, 1)      4           encoder_conv_1[0][0]             \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_leakyrelu_1 (LeakyReLU) (None, 2000, 1)      0           encoder_norm_1[0][0]             \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_conv_2 (Conv1D)         (None, 2000, 16)     96          encoder_leakyrelu_1[0][0]        \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_norm_2 (BatchNormalizat (None, 2000, 16)     64          encoder_conv_2[0][0]             \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_leakyrelu_2 (LeakyReLU) (None, 2000, 16)     0           encoder_norm_2[0][0]             \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_conv_3 (Conv1D)         (None, 2000, 32)     2592        encoder_leakyrelu_2[0][0]        \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_norm_3 (BatchNormalizat (None, 2000, 32)     128         encoder_conv_3[0][0]             \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_leakyrelu_3 (LeakyReLU) (None, 2000, 32)     0           encoder_norm_3[0][0]             \n",
                        "__________________________________________________________________________________________________\n",
                        "flat_1 (Flatten)                (None, 64000)        0           encoder_leakyrelu_3[0][0]        \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_mu (Dense)              (None, 8)            512008      flat_1[0][0]                     \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_log_variance (Dense)    (None, 8)            512008      flat_1[0][0]                     \n",
                        "__________________________________________________________________________________________________\n",
                        "encoder_output (Lambda)         (None, 8)            0           encoder_mu[0][0]                 \n",
                        "                                                                 encoder_log_variance[0][0]       \n",
                        "==================================================================================================\n",
                        "Total params: 1,026,906\n",
                        "Trainable params: 1,026,808\n",
                        "Non-trainable params: 98\n",
                        "__________________________________________________________________________________________________\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "source": [
                "#inp2 = keras.layers.Input(shape=shape_before_flatten, name=\"encoder_input\")\r\n",
                "x3 = keras.layers.AvgPool1D(2,strides=2,name='red_comp')(bp_lay_1)\r\n",
                "x3 = keras.layers.Flatten(name=\"flat_2\")(x3)\r\n",
                "x3 = keras.layers.Dense(128, activation='relu')(x3)\r\n",
                "x3 = keras.layers.Dropout(0.1)(x3)\r\n",
                "x3 = keras.layers.Dense(32, activation='relu')(x3)\r\n",
                "x3 = keras.layers.Dropout(0.1)(x3)\r\n",
                "x3 = keras.layers.Dense(8, activation='relu')(x3)\r\n",
                "#x3 = keras.Model(inputs=inp, outputs=x3)\r\n",
                "#x3 = keras.layers.concatenate([encoder_mu, encoder_log_variance, x3.output])\r\n",
                "out = keras.layers.Dense(2, activation='softmax')(x3)\r\n",
                "\r\n",
                "full_model = keras.models.Model(inp,out, name=\"classifier\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "source": [
                "encoder.load_weights('encoding_simpler_moreD.h5')\r\n",
                "for l1,l2 in zip(full_model.layers[:11],encoder.layers[0:11]):\r\n",
                "    l1.set_weights(l2.get_weights())\r\n",
                "\r\n",
                "print(full_model.get_weights()[0])\r\n",
                "print(encoder.get_weights()[0])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[[ 0.72829664]]\n",
                        "\n",
                        " [[-0.17327021]]\n",
                        "\n",
                        " [[-0.2218431 ]]\n",
                        "\n",
                        " [[-0.60386807]]\n",
                        "\n",
                        " [[-0.05471272]]]\n",
                        "[[[ 0.72829664]]\n",
                        "\n",
                        " [[-0.17327021]]\n",
                        "\n",
                        " [[-0.2218431 ]]\n",
                        "\n",
                        " [[-0.60386807]]\n",
                        "\n",
                        " [[-0.05471272]]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "for layer in full_model.layers[0:11]:\r\n",
                "    layer.trainable = False\r\n",
                "\r\n",
                "full_model.summary()\r\n",
                "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'full_model' is not defined",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-1-25d4b9656dab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'full_model' is not defined"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "source": [
                "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\r\n",
                "classify_train = full_model.fit(Xtrain, Ytrain, batch_size=128,epochs=50,verbose=1,validation_split=0.2,shuffle=True,callbacks=[es_callback])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1/50\n",
                        "29/29 [==============================] - 5s 168ms/step - loss: 0.5642 - accuracy: 0.6978 - val_loss: 0.6136 - val_accuracy: 0.6478\n",
                        "Epoch 2/50\n",
                        "29/29 [==============================] - 5s 164ms/step - loss: 0.5607 - accuracy: 0.6958 - val_loss: 0.6033 - val_accuracy: 0.6600\n",
                        "Epoch 3/50\n",
                        "29/29 [==============================] - 5s 165ms/step - loss: 0.5603 - accuracy: 0.7017 - val_loss: 0.6224 - val_accuracy: 0.6589\n",
                        "Epoch 4/50\n",
                        "29/29 [==============================] - 5s 166ms/step - loss: 0.5663 - accuracy: 0.6969 - val_loss: 0.6140 - val_accuracy: 0.6656\n",
                        "Epoch 5/50\n",
                        "29/29 [==============================] - 5s 167ms/step - loss: 0.5573 - accuracy: 0.7022 - val_loss: 0.6147 - val_accuracy: 0.6622\n",
                        "Epoch 6/50\n",
                        "29/29 [==============================] - 5s 184ms/step - loss: 0.5520 - accuracy: 0.7072 - val_loss: 0.6146 - val_accuracy: 0.6678\n",
                        "Epoch 7/50\n",
                        "29/29 [==============================] - 5s 168ms/step - loss: 0.5577 - accuracy: 0.7053 - val_loss: 0.6066 - val_accuracy: 0.6522\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "full_model.save_weights('autoencoder_classification.h5')\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "from sklearn.metrics import classification_report, confusion_matrix\r\n",
                "test_loss, test_acc = full_model.evaluate(np.array(Xtrain), np.array(Ytrain))\r\n",
                "print('Test accuracy:', test_acc)\r\n",
                "Ypred_raw=full_model.predict(np.array(Xtrain))\r\n",
                "Ypred=np.argmax(Ypred_raw, axis=1)\r\n",
                "Ytest_new=np.argmax(Ytrain,axis=1)\r\n",
                "cm = confusion_matrix(Ytest_new, Ypred)\r\n",
                "print(cm)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "141/141 [==============================] - 5s 36ms/step - loss: 0.3155 - accuracy: 0.8956\n",
                        "Test accuracy: 0.8955555558204651\n",
                        "[[2263  170]\n",
                        " [ 300 1767]]\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}