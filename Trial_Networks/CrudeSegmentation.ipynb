{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt to improve the NN\n",
    "#add the local and the global view construct coz transit false positive mismatch seems to be a major problem\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.loadtxt('training_data/Xtrain_av_raw200_2_3d0.csv',delimiter=',')\n",
    "Y_train=np.loadtxt('training_data/Ytrain_av_raw200_2_3d0.csv',delimiter=',')\n",
    "\n",
    "#Xtrain=np.loadtxt('training_data/Xtrain_av_raw500.csv',delimiter=',')\n",
    "#Ytrain=np.loadtxt('training_data/Ytrain_av_raw500.csv',delimiter=',')\n",
    "#Xtest=np.loadtxt('training_data/Xtest_av_raw500.csv',delimiter=',')\n",
    "#Ytest=np.loadtxt('training_data/Ytest_av_raw500.csv',delimiter=',')\n",
    "\n",
    "#arr=np.arange(0,len(Xtrain),1)\n",
    "#arr2=np.arange(0,len(Xtest),1)\n",
    "#np.random.shuffle(arr)\n",
    "#np.random.shuffle(arr2)\n",
    "#Xtrain=np.array([Xtrain[z] for z in arr])\n",
    "#Ytrain=np.array([Ytrain[z] for z in arr])\n",
    "#Xtest=np.array([Xtest[z] for z in arr2])\n",
    "#Ytest=np.array([Ytest[z] for z in arr2])\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "print(Xtrain.shape,Ytrain.shape,Xtest.shape,Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11223)\n",
    "#Ytrain = np.asarray([[0,1] if(el[0]<0.001) else [1,0] for el in Ytrain])\n",
    "#Ytest = np.asarray([[0,1] if(el[0]<0.001) else [1,0] for el in Ytest])\n",
    "#Ytrain=np.asarray([[1,0] if el[0]==1 else [0,1] for el in Ytrain])\n",
    "#Ytest=np.asarray([[1,0] if el[0]==1 else [0,1] for el in Ytest])\n",
    "#print(Ytrain.shape, Ytest.shape)\n",
    "'''\n",
    "kernel_size = 3\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "Xtrain = [np.convolve(Xtrain[i], kernel, mode='same') for i in range(len(Xtrain))]\n",
    "Xtest = [np.convolve(Xtest[i], kernel, mode='same') for i in range(len(Xtest))]\n",
    "'''\n",
    "vararr=np.random.randint(0,len(Xtrain),size=10)\n",
    "fig,ax=plt.subplots(10,1,figsize=(10,20))\n",
    "\n",
    "for i in range(0,10):\n",
    "    ax[i].plot(Xtrain[vararr[i]],label=Ytrain[vararr[i]])\n",
    "    ax[i].legend()\n",
    "plt.show\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE=200\n",
    "conv_ip = keras.layers.Input(shape=(IMG_SIZE,),name='Input')\n",
    "x=keras.layers.Reshape((IMG_SIZE, 1), input_shape=(IMG_SIZE,),name='reshape_1')(conv_ip)\n",
    "x=keras.layers.BatchNormalization()(x)\n",
    "x=keras.layers.Conv1D(16,kernel_size=3,strides=1,activation='tanh',padding='same',name='second_conv16_5')(x)\n",
    "x=keras.layers.Conv1D(16,kernel_size=3,strides=1,activation='tanh',padding='same',name='third_conv16_5')(x) \n",
    "\n",
    "x=keras.layers.MaxPool1D(3,strides=2 ,data_format='channels_last',padding='same',name='maxpool_1')(x)  #800\n",
    "x=keras.layers.Conv1D(32,kernel_size=3,strides=1,activation='tanh',padding='same',name='second_conv32_5')(x)\n",
    "x=keras.layers.Conv1D(32,kernel_size=3,strides=1,activation='tanh',padding='same',name='third_conv32_5')(x)\n",
    "\n",
    "x=keras.layers.MaxPool1D(3,strides=2,data_format='channels_last',padding='same',name='maxpool_2')(x)  #400\n",
    "x=keras.layers.Conv1D(64,kernel_size=3,strides=1,activation='tanh',padding='same',name='second_conv64_5')(x)\n",
    "x=keras.layers.Conv1D(64,kernel_size=3,strides=1,activation='tanh',padding='same',name='third_conv64_5')(x)\n",
    "\n",
    "#x=keras.layers.MaxPool1D(3,strides=1,data_format='channels_last',padding='same',name='maxpool_4')(x)  #400\n",
    "#x=keras.layers.Conv1D(128,kernel_size=3,strides=1,activation='tanh',padding='same',name='second_conv64_6')(x)\n",
    "#x=keras.layers.Conv1D(128,kernel_size=3,strides=1,activation='tanh',padding='same',name='third_conv64_6')(x)\n",
    "    \n",
    "x=keras.layers.MaxPool1D(3,strides=1,data_format='channels_last',padding='same',name='maxpool_3')(x)    #200\n",
    "\n",
    "x = keras.layers.Flatten(name='flat_1')(x)\n",
    "\n",
    "x3=keras.layers.Dense(256,name='dense_layer_1',activation='relu')(x)\n",
    "x3=keras.layers.Dense(256,name='dense_layer_2',activation='relu')(x3)\n",
    "x3=keras.layers.Dense(256,name='dense_layer_3',activation='relu')(x3)\n",
    "\n",
    "x3=keras.layers.Dense(1,name='dense_layer_5',activation='relu')(x3)\n",
    "conv_op=keras.layers.Dense(2,name='dense_layer_6',activation='softmax')(x3)\n",
    "\n",
    "convNN = keras.Model(inputs=conv_ip, outputs=conv_op,name='Convolutional_NN')\n",
    "\n",
    "convNN.summary()\n",
    "convNN.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00005), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history=convNN.fit(np.asarray(Xtrain),np.asarray(Ytrain), batch_size=64, epochs=30 , verbose=1 ,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('present_LC_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('present_LC_cnn_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNN.save('present_raw_cnn_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNN.load_weights('need_These.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = convNN.evaluate(np.array(Xtest), np.array(Ytest))\n",
    "print('Test accuracy:', test_acc)\n",
    "Ypred_raw=convNN.predict(np.array(Xtest))\n",
    "Ypred=np.argmax(Ypred_raw, axis=1)\n",
    "Ytest_new=np.argmax(Ytest,axis=1)\n",
    "cm = confusion_matrix(Ytest_new, Ypred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes no sense without a background!!!\n",
    "from astropy.io import ascii\n",
    "ent = 1\n",
    "test_entry=os.listdir('test_data_raw200/xlabel/')\n",
    "#print(test_entry)\n",
    "Xexp=np.loadtxt('test_data_raw200/xlabel/'+test_entry[ent])\n",
    "Yexp_tr = np.loadtxt('test_data_raw200/ylabel/'+test_entry[ent]) \n",
    "\n",
    "av_entry=ascii.read('autovetter_label.tab')\n",
    "av_pl=np.array(av_entry['tce_plnt_num'])\n",
    "ref_kepid=[('0000'+str(el)[:9])[-9:] for el in av_entry['kepid']]\n",
    "ref_label=av_entry['av_training_set']\n",
    "\n",
    "loc= np.where(np.array(ref_kepid)==test_entry[ent][0:9])\n",
    "loc_f=[m for m in loc[0] if str(av_pl[m])==test_entry[ent][10]]\n",
    "print(ref_label[loc_f[0]])\n",
    "\n",
    "\n",
    "Yexp=np.argmax(convNN.predict(np.array(Xexp)),axis=1)\n",
    "stXexp=np.concatenate(Xexp)\n",
    "stYexp=[el*np.ones(100) for el in Yexp]\n",
    "stYexp_tr=[el[0]*np.ones(100) for el in Yexp_tr]\n",
    "stYexp=np.concatenate(stYexp)\n",
    "stYexp_tr=np.concatenate(stYexp_tr)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(stXexp)\n",
    "plt.title(\"predictions\")\n",
    "plt.plot(stYexp*min(stXexp),label=ref_label[loc_f[0]])\n",
    "plt.plot(stYexp_tr*min(stXexp),label=\"true\",color='black')\n",
    "plt.legend()\n",
    "#print(Yexp)\n",
    "plt.xlim(10000,25000)\n",
    "#plt.ylim(-0.005,0.015)\n",
    "plt.savefig(\"testing_PL_sample_3.png\")\n",
    "#Y=convNN.predict(np.array(Xexp))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
