{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_size=2000\n",
                "np.random.seed(1234567)\n",
                "#loading data and fitting follows:\n",
                "Xtrain=np.loadtxt('training_data/Xtrain_big.csv',delimiter=',')\n",
                "Ytrain=np.loadtxt('training_data/YtrainR_big.csv',delimiter=',')\n",
                "#Xtrain=Xtrain[:2000]\n",
                "#Xtrain=np.transpose(Xtrain)\n",
                "print(Xtrain.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#defining a sampling function: returns a random sample from a mean and variance\n",
                "#that is input to it\n",
                "def sampling(mu_log_variance):\n",
                "    mu, log_variance = mu_log_variance\n",
                "    epsilon = keras.backend.random_normal(shape=keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
                "    random_sample = mu + keras.backend.exp(log_variance/2) * epsilon\n",
                "    return random_sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#model defined here\n",
                "inp = keras.layers.Input(shape=(img_size, 1), name=\"encoder_input\")\n",
                "#leaky reLU has been added as a separate layer than define as an activation\n",
                "x1 = keras.layers.Conv1D(filters=1, kernel_size=5, padding=\"same\", strides=1,name=\"encoder_conv_1\")(inp)\n",
                "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_1\")(x1)\n",
                "x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(x1)\n",
                "\n",
                "x1 = keras.layers.Conv1D(filters=16, kernel_size=5, padding=\"same\", strides=1, name=\"encoder_conv_2\")(x1)\n",
                "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_2\")(x1)\n",
                "x1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(x1)\n",
                "\n",
                "x1 = keras.layers.Conv1D(filters=32, kernel_size=5, padding=\"same\", strides=1, name=\"encoder_conv_3\")(x1)\n",
                "x1 = keras.layers.BatchNormalization(name=\"encoder_norm_3\")(x1)\n",
                "bp_lay_1 = keras.layers.LeakyReLU(name=\"encoder_leakyrelu_3\")(x1)\n",
                "#flatten the layers in encoder\n",
                "shape_before_flatten = keras.backend.int_shape(bp_lay_1)[1:]\n",
                "x2 = keras.layers.Flatten(name=\"flat_1\")(bp_lay_1)\n",
                "\n",
                "latent_space_dim = 8\n",
                "#declare a mean and variance for the distribution\n",
                "encoder_mu = keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(x2)\n",
                "encoder_log_variance = keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(x2)\n",
                "encoder_op = keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
                "\n",
                "encoder = keras.models.Model(inp, encoder_op, name=\"encoder_model\")\n",
                "encoder.summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#decoder_input = keras.layers.Input(shape=(shape_before_flatten), name=\"decoder_input\")\n",
                "decoder_input = keras.layers.Input(shape=(latent_space_dim), name=\"decoder_input\")\n",
                "x3 = keras.layers.Dense(units=np.prod(shape_before_flatten), name=\"decoder_dense_1\")(decoder_input)\n",
                "x3 = keras.layers.Reshape(target_shape=shape_before_flatten)(x3)\n",
                "\n",
                "x3 = keras.layers.Conv1DTranspose(filters=32, kernel_size=5, padding=\"same\", strides=1, name=\"decoder_conv_tran_1\")(x3)\n",
                "x3 = keras.layers.BatchNormalization(name=\"decoder_norm_1\")(x3)\n",
                "x3 = keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(x3)\n",
                "\n",
                "x3 = keras.layers.Conv1DTranspose(filters=16, kernel_size=5, padding=\"same\", strides=1, name=\"decoder_conv_tran_2\")(x3)\n",
                "x3 = keras.layers.BatchNormalization(name=\"decoder_norm_2\")(x3)\n",
                "x3 = keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(x3)\n",
                "\n",
                "decoder_output = keras.layers.Conv1DTranspose(filters=1, kernel_size=5, padding=\"same\", strides=1,activation='sigmoid', name=\"decoder_conv_tran_4\")(x3)\n",
                "#decoder_output = keras.layers.LeakyReLU(name=\"decoder_output\")(x3)\n",
                "\n",
                "decoder = keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
                "decoder.summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras import backend as K\n",
                "def loss_func(encoder_mu, encoder_log_variance):\n",
                "    def vae_reconstruction_loss(y_true, y_predict):\n",
                "        reconstruction_loss_factor = 1000\n",
                "        reconstruction_loss = keras.backend.mean(keras.backend.square(y_true-y_predict), axis=[1, 2])\n",
                "        return reconstruction_loss_factor * reconstruction_loss\n",
                "\n",
                "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
                "        kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
                "        return kl_loss\n",
                "\n",
                "    def vae_kl_loss_metric(y_true, y_predict):\n",
                "        kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
                "        return kl_loss\n",
                "\n",
                "    def vae_loss(y_true, y_predict):\n",
                "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
                "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
                "\n",
                "        loss = reconstruction_loss + kl_loss\n",
                "        return loss\n",
                "\n",
                "    return vae_loss\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#model for the vae\n",
                "vae_input = keras.layers.Input(shape=(img_size,1), name=\"VAE_input\")\n",
                "vae_encoder_output = encoder(vae_input)\n",
                "vae_decoder_output = decoder(vae_encoder_output)\n",
                "vae = keras.models.Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
                "\n",
                "vae.summary()\n",
                "#vae.compile(optimizer=keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
                "vae.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0005), loss=loss_func(encoder_mu, encoder_log_variance))\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Xtrain_N=[]\n",
                "#[Xtrain_N.append(Xtrain[i]/np.abs(Xtrain[i][np.argmin(Xtrain[i])])) for i in range(0,3231)]\n",
                "#Xtrain=np.array(Xtrain_N).reshape(3231,12000,1)\n",
                "arr=np.arange(0,4500,1)\n",
                "np.random.shuffle(arr)\n",
                "Xtrain=np.array([Xtrain[i] for i in arr])\n",
                "Xtrain=np.array(Xtrain).reshape(4500,2000,1)\n",
                "Xtrain=Xtrain[0:4500]\n",
                "print(Xtrain.shape)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
                "history=vae.fit(Xtrain, Xtrain, epochs=30, batch_size=64 ,verbose=1, validation_split=0.2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vae.save_weights('autoencoder_simpler_moreD.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder.save_weights('encoding_simpler_moreD.h5')\n",
                "decoder.save_weights('decoding_simpler_moreD.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
        },
        "kernelspec": {
            "display_name": "Python 3.9.5 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
