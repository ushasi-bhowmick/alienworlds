{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "#long awaited keras tutorial... coz basic idea is a good idea...\r\n",
                "from keras.models import Sequential\r\n",
                "import tensorflow as tf\r\n",
                "from keras.layers import Dense, Activation, Dropout"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "#three categories of keras API - model, layer and Core modules\r\n",
                "#model represents an ANN - each model is a collection of different layers... represent diffrent layers of an ANN\r\n",
                "#keras model: sequential: linear composition of keras layers\r\n",
                "\r\n",
                "model=Sequential()\r\n",
                "model.add(Dense(512, activation='relu', input_shape=(784,)))\r\n",
                "#like in C++ we need to create a model instance and add layers to it. \r\n",
                "#We can have different calls of the constructor as well"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "#layers: each corresponding layer of the proposed Neural Network\r\n",
                "#Important keras layers : Core, convolution, pooling, recurrent\r\n",
                "#we can create customised layers as well\r\n",
                "model.add(Dense(512, activation='relu', input_shape=(784,)))\r\n",
                "model.add(Dropout(0.2))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "#core modules: activation, loss, optimizer, regularizers, initializers, constraints, metrics etc\r\n",
                "#backend: keras runs on tensorflow backend\r\n",
                "from keras import backend as k \r\n",
                "k.get_uid(prefix='') #initializer for default graph\r\n",
                "k.reset_uids() #reset the uid value\r\n",
                "data = k.placeholder(shape=(1,3,3),dtype='float32') #create a placeholder tensor of a desired shape\r\n",
                "k.int_shape(data)   #show the shape of data\r\n",
                "a=k.placeholder(shape=(3,3)) \r\n",
                "b=k.placeholder(shape=(3,3))\r\n",
                "c=k.dot(a,b) #dot product of two tensors\r\n",
                "res = k.ones(shape=(2,2)) #initialize a tensor with all values 1\r\n",
                "d=k.batch_dot(a,b) #execute a batch dot ... no idea what that is\r\n",
                "var = k.variable([[1,2,3],[4,5,6]])  #create a variable... unlike placeholders, their value can be altered at runtime\r\n",
                "res = k.transpose(var) #transpose of a variable\r\n",
                "print(k.eval(res)) #display only array from the tensor specs\r\n",
                "\r\n",
                "e=k.placeholder((2,2), sparse=True) #ig it means the row and column is dynamic to change\r\n",
                "print(k.is_sparse(e)) #check if a tensor is sparse. prints true in this case\r\n",
                "f=k.to_dense(e) #convert a sparse tensor to a dense tensor, where rows and cols are fixed in dimensionality\r\n",
                "g=k.random_uniform_variable(shape=(2,2), low=1, high=10) #declare a uniform random variable of a particular shape and range"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "KerasTensor(type_spec=TensorSpec(shape=(3, 3), dtype=tf.float32, name=None), name='tf.linalg.matmul/MatMul:0', description=\"created by layer 'tf.linalg.matmul'\")\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "#utilities of keras\r\n",
                "labels=[0,1,2,3,4,5,6,7,8,9]\r\n",
                "cat_label=tf.keras.utils.to_categorical(labels) #convert neural net to binary format for classification\r\n",
                "n=tf.keras.utils.normalize([1,2,3,4,5]) #normalize the input vector\r\n",
                "tf.keras.utils.plot_model(model, to_file='model_im.png') #generate an image version of the model"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "#for a keras layer to work the following things must be specified: \r\n",
                "#shape of input data, no. of neurons, initializer, regularizer, constraint, activation\r\n",
                "from keras import initializers,constraints,regularizers\r\n",
                "\r\n",
                "model.add(Dense(32, input_shape=(16,), kernel_initializer = 'he_uniform', \r\n",
                "   kernel_regularizer = None, kernel_constraint = 'MaxNorm', activation = 'relu')) \r\n",
                "\r\n",
                "my_init=initializers.Zeros()\r\n",
                "my_constrain=constraints.MaxNorm(max_value=2,axis=0)\r\n",
                "my_reg=regularizers.l1(0.)\r\n",
                "model.add(Dense(32, input_shape=(16,), kernel_initializer = my_init, \r\n",
                "   kernel_regularizer = my_reg, kernel_constraint = 'MaxNorm', activation = 'relu')) \r\n",
                "#initializers: set initial vales for weights and biases ig\r\n",
                "initializers.Ones()\r\n",
                "initializers.Constant(value=0)\r\n",
                "initializers.RandomNormal(mean=0.0,stddev=0.05,seed=None)\r\n",
                "initializers.RandomUniform(minval=-0.05,maxval=0.05,seed=None)\r\n",
                "initializers.TruncatedNormal(mean = 0.0, stddev = 0.05, seed = None)\r\n",
                "initializers.VarianceScaling(scale = 1.0, mode = 'fan_in', distribution = 'normal', seed = None) \r\n",
                "#varaince scale calculates stddev using sqrt(scale/n) and calculates weights using normal distribution. \r\n",
                "#now whether n is input unit, output unit or an average of the two depends on the mode fan_in, fan_out or fan_avg\r\n",
                "#can also calculate limit as sqrt(3*scale/n)\r\n",
                "initializers.lecun_uniform(seed = None) \r\n",
                "initializers.glorot_normal(seed=None) \r\n",
                "initializers.glorot_uniform(seed = None) \r\n",
                "initializers.he_normal(seed = None) \r\n",
                "initializers.Orthogonal(gain = 1.0, seed = None) \r\n",
                "initializers.Identity(gain = 1.0)\r\n",
                "\r\n",
                "#Constraints: constraints on weights and biases help to limit the NN and prevent overfitting\r\n",
                "constraints.NonNeg\r\n",
                "constraints.UnitNorm(axis=0)\r\n",
                "constraints.MinMaxNorm(min_value=0.0,max_value=1.0,rate=1.0,axis=0)\r\n",
                "#rate is rate at which constraint is applied\r\n",
                "\r\n",
                "#regularizers: penalties appllied for overfitting\r\n",
                "regularizers.l2(0.)\r\n",
                "regularizers.l1_l2(0.)\r\n",
                "\r\n",
                "#activations: non-linear tranformation of a layer, enable it to learn better\r\n",
                "#options: linear, elu, selu, relu, softmax, softplus, softsign, tanh, sigmoid, hard_sigmoid, exponential\r\n",
                "#elu means exponential linear unit\r\n",
                "\r\n",
                "#Layer varieties:\r\n",
                "layer_1 = Dense(16, input_shape = (8,))\r\n",
                "#arguments: units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer,\r\n",
                "#kernel_constraint, bias_constraint\r\n",
                "#activity_regularizer applies a regularization constraint on the output\r\n",
                "#input_shape is a special argument given iff the layer specified is the first layer of the NN\r\n",
                "layer_2 = Dropout(0.3, noise_shape=None, seed=None)\r\n",
                "#rate is the fraction of nodes to dropout\r\n",
                "#noise shape represents the dimension of shape in which dropout has to be applied.\r\n",
                "layer_3 = tf.keras.layers.Flatten(data_format=None)\r\n",
                "#flatten the input, get a 2x2 input to 4 array, data_format is an optional argu ment\r\n",
                "layer_4= tf.keras.layers.Reshape((16,8))\r\n",
                "#alter shape of layers\r\n",
                "layer_5= tf.keras.layers.Permute((2,1))\r\n",
                "#if input is say (8,16), output will be a (16,8) matrix... need to know more on this\r\n",
                "layer_6= tf.keras.layers.RepeatVector(16)\r\n",
                "#repeat an input vector a set number of times... if input shape is (x,32), output shape will be (x,16,32)\r\n",
                "#lambda ... transform a layer before input, need to find more about it.\r\n",
                "layer_7=tf.keras.layers.Conv1D(filters=None, kernel_size=4, strides=1, padding='valid',data_format='channels_last')\r\n",
                "layer_8=tf.keras.layers.Conv2D(filters=None, kernel_size=(4,4), strides=(1,1), padding='valid')\r\n",
                "#filters: number of filters to apply in each convolution, affects dimension of output shape\r\n",
                "#kernel size: length of convolution window\r\n",
                "#padding: valid, causal, same(o/p same length as i/p)\r\n",
                "layer_9=tf.keras.layers.MaxPool1D(pool_size=2,strides=None,padding='valid')\r\n",
                "#max pooling operations on temporal data\r\n",
                "layer_10=tf.keras.layers.LocallyConnected1D(16,3,input_shape=(10,8))\r\n",
                "# apply a unshared weight convolution 1-dimension of length 3 to a sequence with 10 timesteps, with 16 output filters\r\n",
                "#just like convolution but with unshared weights\r\n",
                "layer_11=tf.keras.layers.subtract([layer_1,layer_2])\r\n",
                "#other options include add,multiply, average, maximum, minimum, concatenate, dot\r\n",
                "layer_12=tf.keras.layers.Embedding(input_dim=(10,10),output_dim=(5,5))\r\n",
                "#embedding operations: convert positive into dense vectors of fixed size\r\n",
                "\r\n",
                "#common functions associated with layers:\r\n",
                "layer_1.get_weights() #get the weight matrix\r\n",
                "config=layer_1.get_config()   #get configuration of a layer as an object\r\n",
                "reload_layer=Dense.from_config(config) #this configuration can be used to reset layers anytime\r\n",
                "layer_1.input_shape #shape of a single node\r\n",
                "layer_1.input #get input data of single node\r\n",
                "layer_1.get_input_at(8) #get input data at a specified index\r\n",
                "layer_1.get_input_shape_at(8)\r\n",
                "layer_1.output_shape #get output shape\r\n",
                "layer_1.output\r\n",
                "layer_1.get_output_at(7)\r\n",
                "layer_1.get_output_shape_at(4)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "AttributeError",
                    "evalue": "The layer has never been called and thus has no defined input shape.",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-10-4c35e9d53cf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#get configuration of a layer as an object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mreload_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#this configuration can be used to reset layers anytime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;31m#shape of a single node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;31m#get input data of single node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get input data at a specified index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36minput_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \"\"\"\n\u001b[0;32m   2060\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m       raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[0;32m   2062\u001b[0m                            'and thus has no defined input shape.')\n\u001b[0;32m   2063\u001b[0m     all_input_shapes = set(\n",
                        "\u001b[1;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined input shape."
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "#creating custom layers\r\n",
                "from keras import backend as k \r\n",
                "from keras.layers import Layer\r\n",
                "\r\n",
                "#need to define a layer class\r\n",
                "class custom_ly(Layer):\r\n",
                "    #constructor call\r\n",
                "    def __init__(self, output_dim, **kwargs):    \r\n",
                "        self.output_dim = output_dim \r\n",
                "        super(custom_ly, self).__init__(**kwargs)\r\n",
                "    \r\n",
                "    #main method needed to build the layer properly\r\n",
                "    #kernel function that creates the appropriate weight matrix according to our input shape\r\n",
                "    def build(self,input_shape):\r\n",
                "        self.kernel = self.add_weight(name = 'kernel', shape = (input_shape[1], self.output_dim), initializer = 'normal', trainable = True) \r\n",
                "        super(custom_ly, self).build(input_shape)\r\n",
                "\r\n",
                "    #call method:how the layer works during training\r\n",
                "    def call(self, input_data):\r\n",
                "        return(k.dot(input_data,self.kernel))\r\n",
                "    \r\n",
                "    #compute output shape\r\n",
                "    def compute_output_shape(self, input_shape): \r\n",
                "        return (input_shape[0], self.output_dim)\r\n",
                "\r\n",
                "    #these functions are important for creating a custom layer. Now we can use it as an ordinary TF layer\r\n",
                "model = Sequential() \r\n",
                "model.add(custom_ly(32, input_shape = (16,))) \r\n",
                "\r\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "in user code:\n\n    <ipython-input-11-afc888b3f016>:20 call  *\n        return(K.dot(input_data,self.kernel))\n\n    NameError: name 'K' is not defined\n",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-11-afc888b3f016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#these functions are important for creating a custom layer. Now we can use it as an ordinary TF layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_ly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    946\u001b[0m                                                 input_list)\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1081\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1082\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1084\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    854\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mNameError\u001b[0m: in user code:\n\n    <ipython-input-11-afc888b3f016>:20 call  *\n        return(K.dot(input_data,self.kernel))\n\n    NameError: name 'K' is not defined\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}